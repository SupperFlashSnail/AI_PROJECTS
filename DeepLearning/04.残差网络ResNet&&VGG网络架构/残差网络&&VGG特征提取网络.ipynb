{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet残差网络\n",
    "```\n",
    "残差网络是随着网络深度的增加，模型出现退化现象，为了解决这类问题而在网络结构中增加残差网络block，即将block的输入特征值和block中处理后的特征数据累加在一起。\n",
    "具体原因是：有些网络层的特征数据处理通过relu激活函数过滤后遗留的特征较少，此时就把之前未处理的特征数据直接保存下来，至少可以保证特征不会变差。\n",
    "```\n",
    "\n",
    "### 残差网络流程图\n",
    "<img src=\"残差网络流程.jpg\" style='zoom:50%'>\n",
    "\n",
    "### 残差网络残差模块\n",
    "<img src=\"残差网络block.jpg\" style='zoom:50%'>\n",
    "\n",
    "### VGG特征提取网络\n",
    "<img src=\"VGG网络.jpg\" style='zoom:80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow-VGG特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#mnist-data download\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_model(model_type):\n",
    "    numClasses = 10\n",
    "    tf.reset_default_graph()\n",
    "    x = tf.placeholder(\"float\",shape = [None,28,28,1])\n",
    "    y_ = tf.placeholder(\"float\",shape = [None,numClasses])\n",
    "    \n",
    "    #权重参数定义\n",
    "    W_conv1_1 = tf.Variable(tf.truncated_normal(shape = [3,3,1,16],stddev=0.1))\n",
    "    b_conv1_1 = tf.Variable(tf.constant(0.1,shape = [16]))\n",
    "\n",
    "    W_conv1_2 = tf.Variable(tf.truncated_normal(shape = [3,3,16,16],stddev=0.1))\n",
    "    b_conv1_2 = tf.Variable(tf.constant(0.1,shape = [16]))\n",
    "\n",
    "    #pool1_ksize   = [1,2,2,1]\n",
    "    #pool1_strides = [1,2,2,1]\n",
    "\n",
    "    W_conv2_1 = tf.Variable(tf.truncated_normal(shape = [3,3,16,32],stddev=0.1))\n",
    "    b_conv2_1 = tf.Variable(tf.constant(0.1,shape = [32]))\n",
    "\n",
    "    W_conv2_2 = tf.Variable(tf.truncated_normal(shape = [3,3,32,32],stddev=0.1))\n",
    "    b_conv2_2 = tf.Variable(tf.constant(0.1,shape = [32]))\n",
    "\n",
    "    pool2_ksize   = [1,2,2,1]\n",
    "    pool2_strides = [1,2,2,1]\n",
    "\n",
    "    W_conv3_1 = tf.Variable(tf.truncated_normal(shape = [3,3,32,64],stddev=0.1))\n",
    "    b_conv3_1 = tf.Variable(tf.constant(0.1,shape = [64]))\n",
    "\n",
    "    W_conv3_2 = tf.Variable(tf.truncated_normal(shape = [3,3,64,64],stddev=0.1))\n",
    "    b_conv3_2 = tf.Variable(tf.constant(0.1,shape = [64]))\n",
    "\n",
    "    W_conv3_3 = tf.Variable(tf.truncated_normal(shape = [3,3,64,64],stddev=0.1))\n",
    "    b_conv3_3 = tf.Variable(tf.constant(0.1,shape = [64]))\n",
    "\n",
    "    ##pool3_ksize   = [1,2,2,1]\n",
    "    ##pool3_strides = [1,2,2,1]\n",
    "\n",
    "    W_conv4_1 = tf.Variable(tf.truncated_normal(shape = [3,3,64,128],stddev=0.1))\n",
    "    b_conv4_1 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "    W_conv4_2 = tf.Variable(tf.truncated_normal(shape = [3,3,128,128],stddev=0.1))\n",
    "    b_conv4_2 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "    W_conv4_3 = tf.Variable(tf.truncated_normal(shape = [3,3,128,128],stddev=0.1))\n",
    "    b_conv4_3 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "    pool4_ksize   = [1,2,2,1]\n",
    "    pool4_strides = [1,2,2,1]\n",
    "\n",
    "    W_conv5_1 = tf.Variable(tf.truncated_normal(shape = [3,3,128,128],stddev=0.1))\n",
    "    b_conv5_1 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "    W_conv5_2 = tf.Variable(tf.truncated_normal(shape = [3,3,128,128],stddev=0.1))\n",
    "    b_conv5_2 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "    W_conv5_3 = tf.Variable(tf.truncated_normal(shape = [3,3,128,128],stddev=0.1))\n",
    "    b_conv5_3 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "    #pool5_ksize   = [1,2,2,1]\n",
    "    #pool5_strides = [1,2,2,1]\n",
    "\n",
    "    W_fc6 = tf.Variable(tf.truncated_normal([7*7*128,1024],stddev = 0.1))\n",
    "    b_fc6 = tf.Variable(tf.constant(0.1,shape = [1024])) \n",
    "\n",
    "    KEEP_DROP_fc6 = 0.5\n",
    "\n",
    "    W_fc7 = tf.Variable(tf.truncated_normal([1024,1024],stddev = 0.1))\n",
    "    b_fc7 = tf.Variable(tf.constant(0.1,shape = [1024])) \n",
    "\n",
    "    KEEP_DROP_fc7 = 0.5\n",
    "\n",
    "    W_fc8 = tf.Variable(tf.truncated_normal([1024,10],stddev = 0.1))\n",
    "    b_fc8 = tf.Variable(tf.constant(0.1,shape = [numClasses]))\n",
    "    \n",
    "    #网络搭建\n",
    "    h_conv1_1 = tf.nn.conv2d(input = x,filter = W_conv1_1,strides = [1,1,1,1],padding = 'SAME') + b_conv1_1\n",
    "    h_conv1_1 = tf.nn.relu(h_conv1_1)\n",
    "\n",
    "    h_conv1_2 = tf.nn.conv2d(input = h_conv1_1,filter = W_conv1_2,strides = [1,1,1,1],padding = 'SAME') + b_conv1_2\n",
    "    h_conv1_2 = tf.nn.relu(h_conv1_2)\n",
    "\n",
    "    h_conv2_1 = tf.nn.conv2d(input = h_conv1_2,filter = W_conv2_1,strides = [1,1,1,1],padding = 'SAME') + b_conv2_1\n",
    "    h_conv2_1 = tf.nn.relu(h_conv2_1)\n",
    "\n",
    "    h_conv2_2 = tf.nn.conv2d(input = h_conv2_1,filter = W_conv2_2,strides = [1,1,1,1],padding = 'SAME') + b_conv2_2\n",
    "    h_conv2_2 = tf.nn.relu(h_conv2_2)\n",
    "\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2_2,ksize = pool2_ksize,strides = pool2_strides,padding='SAME')\n",
    "\n",
    "    h_conv3_1 = tf.nn.conv2d(input = h_pool2,filter = W_conv3_1,strides = [1,1,1,1],padding = 'SAME') + b_conv3_1\n",
    "    h_conv3_1 = tf.nn.relu(h_conv3_1)\n",
    "\n",
    "    h_conv3_2 = tf.nn.conv2d(input = h_conv3_1,filter = W_conv3_2,strides = [1,1,1,1],padding = 'SAME') + b_conv3_2\n",
    "    h_conv3_2 = tf.nn.relu(h_conv3_2)\n",
    "\n",
    "    h_conv3_3 = tf.nn.conv2d(input = h_conv3_2,filter = W_conv3_3,strides = [1,1,1,1],padding = 'SAME') + b_conv3_3\n",
    "    if model_type == 'ResNet':\n",
    "        h_conv3_3 = tf.nn.relu(h_conv3_3)\n",
    "    elif model_type == 'VGG16':\n",
    "        h_conv3_3 = tf.nn.relu(h_conv3_3 + h_conv3_1)\n",
    "    else:\n",
    "        print('error model_type input')\n",
    "        return\n",
    "\n",
    "    #h_pool3 = tf.nn.max_pool(h_conv3_3,ksize = pool3_ksize,strides = pool3_strides,padding='SAME')\n",
    "\n",
    "    h_conv4_1 = tf.nn.conv2d(input = h_conv3_3,filter = W_conv4_1,strides = [1,1,1,1],padding = 'SAME') + b_conv4_1\n",
    "    h_conv4_1 = tf.nn.relu(h_conv4_1)\n",
    "\n",
    "    h_conv4_2 = tf.nn.conv2d(input = h_conv4_1,filter = W_conv4_2,strides = [1,1,1,1],padding = 'SAME') + b_conv4_2\n",
    "    h_conv4_2 = tf.nn.relu(h_conv4_2)\n",
    "\n",
    "    h_conv4_3 = tf.nn.conv2d(input = h_conv4_2,filter = W_conv4_3,strides = [1,1,1,1],padding = 'SAME') + b_conv4_3\n",
    "    \n",
    "    if model_type == 'ResNet':\n",
    "        h_conv4_3 = tf.nn.relu(h_conv4_3)\n",
    "    elif model_type == 'VGG16':\n",
    "        h_conv4_3 = tf.nn.relu(h_conv4_3 + h_conv4_1)\n",
    "    else:\n",
    "        print('error model_type input')\n",
    "        return\n",
    "\n",
    "    h_pool4 = tf.nn.max_pool(h_conv4_3,ksize = pool4_ksize,strides = pool4_strides,padding='SAME')\n",
    "\n",
    "    h_conv5_1 = tf.nn.conv2d(input = h_pool4,filter = W_conv5_1,strides = [1,1,1,1],padding = 'SAME') + b_conv5_1\n",
    "    h_conv5_1 = tf.nn.relu(h_conv5_1)\n",
    "\n",
    "    h_conv5_2 = tf.nn.conv2d(input = h_conv5_1,filter = W_conv5_2,strides = [1,1,1,1],padding = 'SAME') + b_conv5_2\n",
    "    h_conv5_2 = tf.nn.relu(h_conv5_2)\n",
    "\n",
    "    h_conv5_3 = tf.nn.conv2d(input = h_conv5_2,filter = W_conv5_3,strides = [1,1,1,1],padding = 'SAME') + b_conv5_3\n",
    "    if model_type == 'ResNet':\n",
    "        h_conv5_3 = tf.nn.relu(h_conv5_3 + h_conv5_1)\n",
    "    elif model_type == 'VGG16':\n",
    "        h_conv5_3 = tf.nn.relu(h_conv5_3 + h_conv5_1)\n",
    "    else:\n",
    "        print('error model_type input')\n",
    "        return\n",
    "    \n",
    "    #h_pool5 = tf.nn.max_pool(h_conv5_3,ksize = pool5_ksize,strides = pool5_strides,padding='SAME')\n",
    "\n",
    "    h_pool5_flat = tf.reshape(h_conv5_3,[-1,7*7*128])\n",
    "    h_fc6        = tf.nn.relu(tf.matmul(h_pool5_flat,W_fc6) + b_fc6)\n",
    "\n",
    "    h_fc6_drop = tf.nn.dropout(h_fc6,KEEP_DROP_fc6)\n",
    "\n",
    "    h_fc7        = tf.nn.relu(tf.matmul(h_fc6_drop,W_fc7) + b_fc7)\n",
    "\n",
    "    h_fc7_drop = tf.nn.dropout(h_fc7,KEEP_DROP_fc7)\n",
    "\n",
    "    y = tf.matmul(h_fc7_drop,W_fc8) + b_fc8\n",
    "    \n",
    "    #网络训练\n",
    "    with tf.name_scope('loss'):\n",
    "        crossEntropyLoss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_,logits = y),name = 'loss')\n",
    "        tf.summary.scalar(\"loss\", crossEntropyLoss)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        trainStep = tf.train.AdamOptimizer().minimize(crossEntropyLoss) \n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"),name='accuracy')\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    summ = tf.summary.merge_all( )\n",
    "    \n",
    "    if model_type == 'ResNet':\n",
    "        tenboard_dir = './tensorboard/ResNet/'\n",
    "    elif model_type == 'VGG16':\n",
    "        tenboard_dir = './tensorboard/VGG16/'\n",
    "    else:\n",
    "        print('error model_type input')\n",
    "        return\n",
    "\n",
    "    \n",
    "    writer = tf.summary.FileWriter(tenboard_dir)\n",
    "\n",
    "    saver = tf.train.Saver( )    #模型保存句柄\n",
    "\n",
    "    with tf.Session() as  sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        batchSize = 50\n",
    "        writer.add_graph(sess.graph)\n",
    "        \n",
    "        print('=========='+model_type+' training start========')\n",
    "        for i in range(1000):\n",
    "            batch = mnist.train.next_batch(batchSize)\n",
    "            trainingInputs = batch[0].reshape([batchSize,28,28,1])\n",
    "            trainingLabels = batch[1]\n",
    "            if i%100 == 0:\n",
    "                trainAccuracy = accuracy.eval(session=sess, feed_dict={x:trainingInputs, y_: trainingLabels})\n",
    "                print (\"step %d, training accuracy %g\"%(i, trainAccuracy))\n",
    "            if i%5 == 0:\n",
    "                [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x:trainingInputs, y_: trainingLabels})\n",
    "                writer.add_summary(s, i)\n",
    "            if i>=900 and i%20 == 0:\n",
    "                saver.save(sess, './mnist-model/mnist/'+ model_type,global_step=i)\n",
    "            trainStep.run(session=sess, feed_dict={x: trainingInputs, y_: trainingLabels})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========VGG16 training start========\n",
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.4\n",
      "step 200, training accuracy 0.66\n",
      "step 300, training accuracy 0.7\n",
      "step 400, training accuracy 0.66\n",
      "step 500, training accuracy 0.74\n",
      "step 600, training accuracy 0.86\n",
      "step 700, training accuracy 0.86\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    model_type_VGG = 'VGG16'\n",
    "    model_type_ResNet = 'ResNet'\n",
    "    mnist_model(model_type_VGG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
