{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA&&RNN&&LSTM\n",
    "```\n",
    "概述：ARIMA RNN LSTM三种算法都会根据预测时刻之前的输入量来预测当前的数据。从基础上的思想上观察，都和脉冲信号的衰减和叠加的原理相似，好比在NT的时间间隔内有N个脉冲信号，且每一个信号的衰减时间是NT，那么在NT时刻的信号量不仅仅需要计算NT时刻的脉冲信号，而且需要前面NT时间间隔内所有信号尚未衰减完的信号。ARIMA RNN LSTM三种算法不同之处在于算法不同。 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA\n",
    "```\n",
    "差分整合移动平均回归模型，首先通过原始数据的d阶差分计算使时间序列数据呈线性平滑变化的趋势，以便于预测；然后再通过预测时刻数据的p阶自相关系数确定有p阶数据对当前预测有影响；载然后通过预测时刻数据的q阶的偏自相关系数的计算确定q阶数据误差对当前数据预测影响较大；最后通过函数ARIMA(p,d,q)即可预测出当前的数据。\n",
    "```\n",
    "预测效果：\n",
    "```\n",
    "ARIMA算法在时间序列预测只能预测较短时间内的趋势而不能观察整体趋势\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN网络\n",
    "```\n",
    "RNN可以处理序列数据的神经网络，在序列预测的过程中会将前一时刻的预测中转数据信息作为当前预测操作的部分源输入数据。如RNN结构图所示。层与层之间通过权值连接，然后通过激活函数的过滤即可得到用于预测结果的特征数据。\n",
    "```\n",
    "<img src=\"RNN.png\" style='zoom:40%;float:left' >\n",
    "\n",
    "\n",
    "在RNN结构图中，每一个箭头代表一次带有权重值的变换。O代表输出，y代表样本给出的确定值，L代表损失函数。\n",
    "注意：图中的W U V是权值共享的；每一个输入值都只和它本身所在的路线建立权连接，不会和别的神经元建立连接。\n",
    "\n",
    "PS：对于W U V矩阵所保存的信息和ARIMA中p d q所表示的含义有些许相似之处，即确定当前时刻之前的输入数据对本次预测结果有贡献大小。\n",
    "\n",
    "U V W超参数求解和BP不同的是，W U两个参数求解过程需要追溯之前所有的输入数据，进而在反向传播计算梯度时，很容易出现梯度消失和梯度爆炸的情况，为了解决梯度消失的情况，一般选择使用relu激活函数，但是即使使用relu激活函数，在当前预测输入之前的输入数据过多时，也会存在梯度消失情况，即RNN网络只能预测 短期记忆问题。为了解决此问题而提出LSTM算法结构。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM\n",
    "```\n",
    "长短期记忆网络是RNN的变体，RNN网络由于梯度消失的原因只能有短期记忆，LSTM通过网络学习单元的门控结构将短期记忆和长期记忆结合起来，并在一定程度上解决了梯度消失的问题。\n",
    "\n",
    "LSTM和RNN不同，新增了一个用于控制细胞状态，即控制遗忘和记住的内容。\n",
    "```\n",
    "\n",
    "遗忘门：选择遗忘的信息，即线性变换和过滤，计算出非特征信息矩阵\n",
    "\n",
    "<img src=\"LSTM遗忘门.png\" style='zoom:60%' >\n",
    "\n",
    "记忆门：选择记忆信息，计算需要更新的门控状态值，然后通过更新门控状态值计算需要保留的信息。\n",
    "\n",
    "<img src=\"LSTM记忆门.png\" style='zoom:50%' >\n",
    "\n",
    "更新门控状态值\n",
    "\n",
    "<img src=\"LSTM门状态更新.png\" style='zoom:50%' >\n",
    "\n",
    "使用门控状态值计算输出值\n",
    "\n",
    "<img src=\"LSTM数据预测.png\" style='zoom:50%' >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 序列数据预测总结\n",
    "```\n",
    "ARIMA 只用于时间序列的数据预测\n",
    "RNN  可以用于时间序列数据预测和短记忆序列数据预测\n",
    "LSTM 可以用于时间序列数据预测和长短序列数据预测\n",
    "\n",
    "PS：对于RNN LSTM网络一般会用于NLP中自然语言语义分析。但是从RNN LSTM算法实现中可以看出，其算法会只能根据历史输入词汇预测当前词的语义，但是这种算法不能涵盖所有语法规则，例如：干啥呀 ? / ?! /~ ，一句话后面根的语气词不同，则表达的意思完全不同，如果只通过前面的词语是如法预测这句话的语义。目前已经有BERT模型可以解决相似的问题。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.基于Tensorflow的Mnist数据集RNN网络实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "mnist = input_data.read_data_sets('data', one_hot=True)\n",
    "print (mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "input_size = 28      # 每行输入28个特征点\n",
    "timestep_size = 28   # 持续输入28行\n",
    "hidden_size = 128    # 隐含层的数量\n",
    "layer_num = 2        # LSTM layer 的层数\n",
    "class_num = 10       # 10分类问题\n",
    "\n",
    "_X = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, class_num])\n",
    "\n",
    "batch_size = tf.placeholder(tf.int32, [])  \n",
    "keep_prob = tf.placeholder(tf.float32, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络结构\n",
    "\n",
    "<img src=\"LSTM网络结构.png\" style='zoom:80%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM细胞结构\n",
    "\n",
    "def lstm_cell():\n",
    "    cell = rnn.LSTMCell(hidden_size, reuse=tf.get_variable_scope().reuse)     #初始化一层神经网络的细胞元\n",
    "    return rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)               #设定神经元的drop率 防止过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-4d8793d10b7b>:4: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-5-181823f51d1a>:3: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:961: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "X = tf.reshape(_X, [-1, 28, 28])\n",
    "\n",
    "mlstm_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(layer_num)], state_is_tuple = True)   #搭建神经网络\n",
    "\n",
    "#用全零来初始化状态\n",
    "init_state = mlstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "\n",
    "#得到每一层的输出结果\n",
    "outputs = list()\n",
    "state = init_state \n",
    "with tf.variable_scope('RNN'):\n",
    "    for timestep in range(timestep_size):\n",
    "        if timestep > 0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        (cell_output, state) = mlstm_cell(X[:, timestep, :],state)\n",
    "        outputs.append(cell_output)\n",
    "h_state = outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0, step 200, training accuracy 0.914062\n",
      "Iter0, step 400, training accuracy 0.929688\n",
      "Iter1, step 600, training accuracy 0.984375\n",
      "Iter1, step 800, training accuracy 0.945312\n",
      "Iter2, step 1000, training accuracy 0.953125\n",
      "test accuracy 0.969\n"
     ]
    }
   ],
   "source": [
    "#Softmax层参数 定义输出函数\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size, class_num], stddev=0.1), dtype=tf.float32)\n",
    "bias = tf.Variable(tf.constant(0.1,shape=[class_num]), dtype=tf.float32)\n",
    "y_pre = tf.nn.softmax(tf.matmul(h_state, W) + bias)\n",
    "\n",
    "\n",
    "# 损失和评估函数\n",
    "cross_entropy = -tf.reduce_mean(y * tf.log(y_pre))\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(1000):\n",
    "    _batch_size = 128\n",
    "    batch = mnist.train.next_batch(_batch_size)\n",
    "    if (i+1)%200 == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={\n",
    "            _X:batch[0], y: batch[1], keep_prob: 1.0, batch_size: _batch_size})\n",
    "        # 已经迭代完成的 epoch 数: mnist.train.epochs_completed\n",
    "        print (\"Iter%d, step %d, training accuracy %g\" % ( mnist.train.epochs_completed, (i+1), train_accuracy))\n",
    "    sess.run(train_op, feed_dict={_X: batch[0], y: batch[1], keep_prob: 0.5, batch_size: _batch_size})\n",
    "\n",
    "# 计算测试数据的准确率\n",
    "print (\"test accuracy %g\"% sess.run(accuracy, feed_dict={\n",
    "    _X: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0, batch_size:mnist.test.images.shape[0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 784) (5, 10)\n",
      "_outputs.shape = (28, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "_batch_size = 5\n",
    "X_batch, y_batch = mnist.test.next_batch(_batch_size)\n",
    "print (X_batch.shape, y_batch.shape)\n",
    "_outputs, _state = sess.run([outputs, state],feed_dict={\n",
    "            _X: X_batch, y: y_batch, keep_prob: 1.0, batch_size: _batch_size})\n",
    "print ('_outputs.shape =', np.asarray(_outputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print (mnist.train.labels[4])\n",
    "\n",
    "X3 = mnist.train.images[4]\n",
    "img3 = X3.reshape([28, 28])\n",
    "plt.imshow(img3, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 1, 128)\n",
      "(28, 128)\n"
     ]
    }
   ],
   "source": [
    "X3.shape = [-1, 784]\n",
    "y_batch = mnist.train.labels[0]\n",
    "y_batch.shape = [-1, class_num]\n",
    "\n",
    "X3_outputs = np.array(sess.run(outputs, feed_dict={\n",
    "            _X: X3, y: y_batch, keep_prob: 1.0, batch_size: 1}))\n",
    "print (X3_outputs.shape)\n",
    "X3_outputs.shape = [28, hidden_size]\n",
    "print (X3_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 28 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_W = sess.run(W, feed_dict={\n",
    "            _X:X3, y: y_batch, keep_prob: 1.0, batch_size: 1})\n",
    "h_bias = sess.run(bias, feed_dict={\n",
    "            _X:X3, y: y_batch, keep_prob: 1.0, batch_size: 1})\n",
    "h_bias.shape = [-1, 10]\n",
    "\n",
    "bar_index = range(class_num)\n",
    "for i in range(X3_outputs.shape[0]):\n",
    "    plt.subplot(7, 4, i+1)\n",
    "    X3_h_shate = X3_outputs[i, :].reshape([-1, hidden_size])\n",
    "    pro = sess.run(tf.nn.softmax(tf.matmul(X3_h_shate, h_W) + h_bias))\n",
    "    plt.bar(bar_index, pro[0], width=0.2 , align='center')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.基于Pytorch的Mnist数据集的RNN网络实现\n",
    "\n",
    "```\n",
    "minist数据集是28×28用于10 分类的数据。在当前例子中使用2层lstm网络层，中间隐层神经元个数为64，对于每一张图分成28次，每次28个特征数据进行输入。输入的每28个特征数据都会计算出64个特征结果，根据lstm的特征，一般选择最后一次输出数据用于特征判别。最后将64个特征数据得到10个得分值，然后对得分值进行交叉熵损失值计算，得到分类。\n",
    "```\n",
    "\n",
    "<img src=\"LSTM数据集.png\" style='zoom:50%'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch  import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = in_channel,\n",
    "            hidden_size = 64,\n",
    "            num_layers = 2,\n",
    "            dropout=0.5)     #默认两层LSTM\n",
    "        self.out = nn.Linear(64,out_channel)\n",
    "        self.h0 = torch.randn(2,28,64)\n",
    "        self.c0 = torch.randn(2,28,64)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output,(h_n,c_n)=self.lstm(x,(self.h0,self.c0))\n",
    "        output_in_last_timestep=output[:,-1,:]\n",
    "        x = F.relu(output_in_last_timestep)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM参数解释：\n",
    "1. https://blog.csdn.net/rogerfang/article/details/84500754\n",
    "2. https://www.zhihu.com/question/41949741/answer/318771336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率评估标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1] \n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum() \n",
    "    return rights, len(labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载数据\n",
    "BATCH_SIZE = 64\n",
    "training_dataset = torchvision.datasets.MNIST(\"./data/mnist\", train=True,\n",
    "                                              transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = Data.DataLoader(dataset=training_dataset,\n",
    "                                      batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "# showSample(dataloader)\n",
    "test_data=torchvision.datasets.MNIST(root=\"./data/mnist\",train=False,\n",
    "                                    transform=torchvision.transforms.ToTensor(),download=False)\n",
    "test_dataloader=Data.DataLoader(\n",
    "    dataset=test_data,batch_size=1000,shuffle=False,num_workers=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata_iter=iter(test_dataloader)\n",
    "test_x,test_y=testdata_iter.next()\n",
    "test_x=test_x.view(-1,28,28)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = 28\n",
    "out_channel = 10\n",
    "net = LSTM(in_channel,out_channel)\n",
    "optimizer=torch.optim.Adam(net.parameters(),lr=0.001)\n",
    "loss_F=torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-0: accuracy:0.126\n",
      "1-0: accuracy:0.132\n",
      "2-0: accuracy:0.133\n",
      "3-0: accuracy:0.133\n",
      "4-0: accuracy:0.133\n",
      "5-0: accuracy:0.133\n",
      "6-0: accuracy:0.133\n",
      "7-0: accuracy:0.133\n",
      "8-0: accuracy:0.133\n",
      "9-0: accuracy:0.133\n",
      "10-0: accuracy:0.133\n",
      "11-0: accuracy:0.133\n",
      "12-0: accuracy:0.133\n",
      "13-0: accuracy:0.133\n",
      "14-0: accuracy:0.133\n",
      "15-0: accuracy:0.133\n",
      "16-0: accuracy:0.133\n",
      "17-0: accuracy:0.133\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "\n",
    "for epoch in range(epochs): # 数据集只迭代一次\n",
    "    for step, input_data in enumerate(dataloader):\n",
    "        x,y=input_data\n",
    "        pred=net(x.view(-1,28,28))\n",
    "\n",
    "        loss=loss_F(pred,y) # 计算loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step/100 == 0: \n",
    "            with torch.no_grad():\n",
    "                test_pred=net(test_x)\n",
    "                prob=torch.nn.functional.softmax(test_pred,dim=1)\n",
    "                pred_cls=torch.argmax(prob,dim=1)\n",
    "                acc=(pred_cls==test_y).sum().numpy()/pred_cls.size()[0]\n",
    "                print(f\"{epoch}-{step}: accuracy:{acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
