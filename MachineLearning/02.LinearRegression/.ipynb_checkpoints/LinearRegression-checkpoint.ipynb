{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression概述\n",
    "\n",
    "线性回归是利用回归分析方式来确定多种变量之间的依赖关系：\n",
    "y = WX+e 其中W为ShapeSize=[1，N]的权重参数 e为预测误差 y为实际值\n",
    "\n",
    "## 线性回归原理图\n",
    "线性回归实际上是求出一个N维的超平面，使所有样本数据都在其上下一定范围内浮动。\n",
    "<img src=\"LinearRegression.png\" >\n",
    "\n",
    "## 线性回归的要求\n",
    "```\n",
    "1. 自变量和因变量之间存在线性关系，可以通过绘制散点图矩阵进行考察\n",
    "2. 自变量和自变量之间相互独立，即自变量之间协方差为0\n",
    "3. 误差服从期望为0独立的正态分布\n",
    "4. 误差大小不会随着变量的变化而变化，即方差齐性\n",
    "```\n",
    "```\n",
    "基本条件的原因分析：\n",
    "y =[θ0，,θ1，θ2，θ3....][X1,X2,X3....] + e 其中特征向量X为因变量，W变量权重，e为预测误差，为固定值，其中e为所有样本预测误差的均值，为一个固定值。自变量和隐变量应该线性相关，否则通过线性表达式则无法诠释样本的分布；自变量和自变量之间相互独立，否则不能进行线性相加；误差服从期望为0独立的正态分布，否则无法满足最大似然估计的条件；误差大小满足齐性，即e是一个固定值，否则不能满足线性方程求解。\n",
    "```\n",
    "\n",
    "## 最大似然估计值\n",
    "```\n",
    "最大似然估计值是求出所有样本预测值和真实值之间的误差之和最小，其表示方法为所有样本预测误差通过正态分布N-(0,u)概率密度的计算后得到概率，然后所有概率的乘积即可得到似然估计值，当所有样本的预测误差都趋近于0，则似然估计值最大，似然估计最大，则表示权重值越正确。\n",
    "```\n",
    "<img src='./maximum.jpg' style='zoom:60%'>\n",
    "\n",
    "```\n",
    "最大似然估计为目标求解函数，在学习的过程中通过梯度下降方式，使目标函数值最大，通过梯度求导，求得每一步的梯度变化方向，然后乘以学习率，最终求出梯度更新尺度。\n",
    "\n",
    "其中梯度数学表达式的物理含义是：所有误差值和对应特征元乘积的期望值\n",
    "```\n",
    "<img src='./grad.png' style='zoom:60%'>\n",
    "\n",
    "```\n",
    "值得注意的是，为了防止过拟合，即使最后学习的W权重能够有更大泛化能力，会在权重更新时加上正则化惩罚项\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features_labels = ['accommodates','bedrooms','bathrooms','beds','price','minimum_nights','maximum_nights','number_of_reviews']\n",
    "features=['accommodates','bedrooms','bathrooms','beds','minimum_nights','maximum_nights','number_of_reviews']\n",
    "\n",
    "dc_listings = pd.read_csv('listings.csv')\n",
    "\n",
    "dc_listings = dc_listings[features_labels]\n",
    "\n",
    "dc_listings['price'] = dc_listings.price.str.replace(\"\\$|,\",'').astype(float) #字符串转换\n",
    "\n",
    "dc_listings = dc_listings[dc_listings.price < 500][dc_listings.price > 100]\n",
    "\n",
    "max_price = dc_listings.price.max()\n",
    "\n",
    "min_price = dc_listings.price.min()\n",
    "\n",
    "dc_listings['price'] = (dc_listings['price']-min_price)/(max_price - min_price) #对价格进行归一化处理\n",
    "\n",
    "dc_listings = dc_listings.dropna()    #去掉空值\n",
    "\n",
    "\n",
    "dc_listings[features] = StandardScaler().fit_transform(dc_listings[features]) #数据标准化处理\n",
    "\n",
    "dc_listings['pad_one'] = 1\n",
    "\n",
    "features.append('pad_one')\n",
    "\n",
    "normalized_listings = dc_listings   #将指定特征数据取出\n",
    "\n",
    "norm_train_df = normalized_listings.copy().iloc[0:2792]\n",
    "norm_test_df = normalized_listings.copy().iloc[2792:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_data = norm_train_df[features]\n",
    "norm_train_label = norm_train_df['price']\n",
    "norm_test_data = norm_test_df[features]\n",
    "norm_test_label = norm_test_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>pad_one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106575</td>\n",
       "      <td>-0.414744</td>\n",
       "      <td>-0.536678</td>\n",
       "      <td>0.107118</td>\n",
       "      <td>-0.308069</td>\n",
       "      <td>-0.022402</td>\n",
       "      <td>-0.541295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.101111</td>\n",
       "      <td>1.803475</td>\n",
       "      <td>2.841286</td>\n",
       "      <td>0.975726</td>\n",
       "      <td>-0.083765</td>\n",
       "      <td>-0.022425</td>\n",
       "      <td>1.835919</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.887961</td>\n",
       "      <td>-0.414744</td>\n",
       "      <td>-0.536678</td>\n",
       "      <td>0.107118</td>\n",
       "      <td>-0.308069</td>\n",
       "      <td>-0.022402</td>\n",
       "      <td>-0.541295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.887961</td>\n",
       "      <td>-0.414744</td>\n",
       "      <td>-0.536678</td>\n",
       "      <td>-0.761489</td>\n",
       "      <td>-0.308069</td>\n",
       "      <td>-0.022402</td>\n",
       "      <td>-0.541295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.887961</td>\n",
       "      <td>-0.414744</td>\n",
       "      <td>-0.536678</td>\n",
       "      <td>-0.761489</td>\n",
       "      <td>-0.308069</td>\n",
       "      <td>-0.022402</td>\n",
       "      <td>-0.541295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accommodates  bedrooms  bathrooms      beds  minimum_nights  \\\n",
       "0       0.106575 -0.414744  -0.536678  0.107118       -0.308069   \n",
       "1       1.101111  1.803475   2.841286  0.975726       -0.083765   \n",
       "17     -0.887961 -0.414744  -0.536678  0.107118       -0.308069   \n",
       "19     -0.887961 -0.414744  -0.536678 -0.761489       -0.308069   \n",
       "21     -0.887961 -0.414744  -0.536678 -0.761489       -0.308069   \n",
       "\n",
       "    maximum_nights  number_of_reviews  pad_one  \n",
       "0        -0.022402          -0.541295        1  \n",
       "1        -0.022425           1.835919        1  \n",
       "17       -0.022402          -0.541295        1  \n",
       "19       -0.022402          -0.541295        1  \n",
       "21       -0.022402          -0.541295        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 通过自己代码实现线性回归预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06575111e-01, -4.14744088e-01, -5.36677939e-01, ...,\n",
       "        -2.24023659e-02, -5.41295306e-01,  1.00000000e+00],\n",
       "       [ 1.10111130e+00,  1.80347496e+00,  2.84128555e+00, ...,\n",
       "        -2.24252374e-02,  1.83591931e+00,  1.00000000e+00],\n",
       "       [-8.87961075e-01, -4.14744088e-01, -5.36677939e-01, ...,\n",
       "        -2.24023659e-02, -5.41295306e-01,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.10111130e+00,  6.94365435e-01, -5.36677939e-01, ...,\n",
       "         4.48325375e+01, -1.02424915e-01,  1.00000000e+00],\n",
       "       [-8.87961075e-01, -4.14744088e-01, -5.36677939e-01, ...,\n",
       "        -2.24254254e-02,  1.21418626e+00,  1.00000000e+00],\n",
       "       [-3.90692982e-01, -1.52385361e+00, -5.36677939e-01, ...,\n",
       "        -2.24023659e-02, -5.04722773e-01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fun(predicts,labels):\n",
    "    loss = labels.flatten() -  predicts.flatten() \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_get(predicts,labels,train_data,theta,lr):\n",
    "    \n",
    "    loss = loss_fun(predicts,labels.values)\n",
    "    grad = np.zeros(len(theta))\n",
    "    for i in range(0,len(theta)):\n",
    "        grad_tmp = 0\n",
    "        for j in range(0,len(train_data)):\n",
    "            grad_tmp = grad_tmp + train_data.values[j][i]*loss[i]\n",
    "        grad[i] = lr*grad_tmp/(len(train_data))\n",
    "    \n",
    "    return grad      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(theta,grad):\n",
    "    theta = theta - grad.reshape(8,1)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8070436718650437\n",
      "-0.8327970458352778\n",
      "-0.8588091155428623\n",
      "-0.8850824796175768\n",
      "-0.9116197627927495\n",
      "-0.9384236161674704\n",
      "-0.9654967174714386\n",
      "-0.9928417713324695\n",
      "-1.0204615095466902\n",
      "-1.0483586913514484\n"
     ]
    }
   ],
   "source": [
    "steps = 100\n",
    "theta = np.ones((8,1))   #定义权重参数\n",
    "lr = 0.001                #定义学习率\n",
    "for step in range(steps):\n",
    "    predicts =  np.dot(norm_train_data.values,theta)\n",
    "    grad = grad_get(predicts,norm_train_label,norm_train_data,theta,lr)\n",
    "    theta = weight_update(theta,grad)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print(loss_fun(predicts,norm_train_label.values).sum()/len(norm_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用SKLEARN库实现线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.78937682781807\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x, y = boston.data, boston.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=10010)\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "y_predict = reg.predict(x_test)\n",
    "print(mean_squared_error(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(379,)\n",
      "[[4.62960e-01 0.00000e+00 6.20000e+00 ... 1.74000e+01 3.76140e+02\n",
      "  5.25000e+00]\n",
      " [1.44760e-01 0.00000e+00 1.00100e+01 ... 1.78000e+01 3.91500e+02\n",
      "  1.36100e+01]\n",
      " [1.12658e+00 0.00000e+00 1.95800e+01 ... 1.47000e+01 3.43280e+02\n",
      "  1.21200e+01]\n",
      " ...\n",
      " [9.76170e-01 0.00000e+00 2.18900e+01 ... 2.12000e+01 2.62760e+02\n",
      "  1.73100e+01]\n",
      " [9.55770e-01 0.00000e+00 8.14000e+00 ... 2.10000e+01 3.06380e+02\n",
      "  1.72800e+01]\n",
      " [3.67822e+00 0.00000e+00 1.81000e+01 ... 2.02000e+01 3.80790e+02\n",
      "  1.01900e+01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([31.7, 19.3, 15.3, 23.7, 22. , 23.9, 23.8, 38.7, 10.2, 21. , 18.2,\n",
       "       19.8, 13. , 11.8, 23.9, 20. , 19.1, 24.7, 34.9, 37.3, 18.7, 19.2,\n",
       "       26.6, 15.6,  8.5, 17.7,  5. , 20.9, 16.7, 17.5, 20.7, 50. ,  8.4,\n",
       "       23.9, 25. , 33.2, 20.1,  8.8, 27.5, 12.1, 24.4, 21.9, 19.7, 18.1,\n",
       "       17.9, 19.8, 17. , 43.5, 19.3, 23.7, 32.2, 20.3, 13.5, 50. , 14.1,\n",
       "       23. , 26.2, 25.3, 11.3, 17.8, 20.5, 21.2, 17.8, 17.2, 25. , 18.6,\n",
       "       15.2, 36.2, 19.5, 20.6, 37.2, 23.2, 24.4, 12.6, 27.9, 21.2, 50. ,\n",
       "       19.9, 24.8, 25. , 29.9, 41.7, 23.1, 12.7, 43.1, 14.9, 22.6, 33.1,\n",
       "        9.5, 27.1, 24.1, 14.2, 29.6, 14.1, 32.5, 18.5, 29.1, 24.4, 18.5,\n",
       "       24.3, 50. , 20.6, 50. ,  7. , 19.4, 22.6, 33.1, 32. , 31. , 24.3,\n",
       "       10.2, 31.1, 17.4, 23.8, 23.9, 15.6, 20. , 34.9, 50. , 18.4, 15.2,\n",
       "       30.8, 13.4, 50. , 20.1, 22.8, 20.8, 22.6, 16.8, 21.4, 16.6, 22. ,\n",
       "       19.6, 24.8, 17.2, 15. , 22.5,  7.5, 18.5, 18.7, 21.2, 27.9, 50. ,\n",
       "       17.4, 19.6, 19.6, 23.5, 24.3, 50. , 45.4, 20.6, 14.6, 23. , 22.9,\n",
       "       28.7, 22.5, 30.1, 48.3, 23.1, 35.2, 28. , 13.4, 20.2, 20.7, 21. ,\n",
       "       20.3, 36. , 16.2, 33.4,  9.7, 34.9, 23.1, 18.4,  8.3, 22.2, 13.4,\n",
       "       11.9, 35.4, 10.9, 27.5, 24.5, 13.1, 16. , 22.9, 10.4, 50. , 48.5,\n",
       "       16.1, 33.2, 16.1, 21.7, 22.8, 19.1, 34.7,  7.2, 23.8, 21.5,  8.8,\n",
       "       21.8, 20.1, 30.1, 24.7, 21.8, 10.5, 31.5, 21.7, 13.9,  7.2, 35.4,\n",
       "        5. , 18.5, 36.1, 19.3, 33.4, 19.6, 24.2, 10.5, 19.9, 16.1, 24.7,\n",
       "       19.8, 20.5, 22.8, 37.6, 19.9, 21.4, 50. ,  9.6, 22.4, 28.7, 14.4,\n",
       "       22. , 20.4, 19.3, 32.4, 24.8, 24.6, 22.4, 16.3, 15.6, 18.8, 17.8,\n",
       "       31.6, 28.1, 13.8, 14.5, 18. , 13.8, 23.3, 24.6,  8.7, 22.3, 29.8,\n",
       "       22.6, 21.9, 19. ,  5.6, 25. , 19.3, 11.8, 13.3, 21.5, 20.1, 22. ,\n",
       "       28.4, 30.1, 19.4, 24.8, 16.4, 19.5, 36.2, 14.5, 16.7, 12. , 21.1,\n",
       "       18.4, 50. , 46. , 25. , 23.2, 20.2, 16.2, 12.3, 25. , 14.9, 50. ,\n",
       "       23.9, 17.4, 24.5, 24. , 13.6, 23.1, 10.2, 34.6, 17.6, 13.1, 28.7,\n",
       "        7. , 42.8, 19.4, 29. , 20.5, 48.8,  8.3, 19.1, 44. , 33. , 13.8,\n",
       "       20. , 15.2, 22.2, 23.4, 12.8, 13.8, 23.1, 20.6,  8.5, 13.1, 18.2,\n",
       "       22.6, 22.7, 16.5,  6.3, 20. , 16.8, 14.9, 22.5, 50. , 23.6, 29. ,\n",
       "       18.2, 36.4, 24.1, 50. , 23.4, 21.6, 30.3, 19.7, 17.1, 18.9, 22.9,\n",
       "       29.8, 11.7, 23. , 22. , 18.3, 11.5, 23.3, 30.5, 32.9, 23.2, 28.5,\n",
       "       37. , 32. , 20.4, 33.3, 27.1, 26.5, 31.5,  8.1, 20.6, 15.1, 23.8,\n",
       "       23.1, 15. , 19.4, 12.5, 17.2, 23.1, 22.2, 20.6, 31.6, 27.5, 13.9,\n",
       "       21.7, 27. , 15.6, 14.8, 20.8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.使用pytorch实现线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLinearRegression(nn.Module):\n",
    "    def __init__(self,InputChanels,OutPutChanels):\n",
    "        super().__init__()\n",
    "        self.out = nn.Linear(InputChanels,OutPutChanels)\n",
    "    def forward(self,x):\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x, y = boston.data, boston.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=10010)\n",
    "\n",
    "def  DataGet(x_train, x_test, y_train, y_test,bs):\n",
    "    x_train, x_test, y_train, y_test = map(torch.tensor,(x_train, x_test, y_train, y_test))\n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "    valid_ds = TensorDataset(x_test, y_test)\n",
    "    valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "    return train_dl,valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def GetModelWithOptAndLossFunc(InputChanels,OutPutChanels):\n",
    "    model = XLinearRegression(InputChanels,OutPutChanels)\n",
    "    opt = optim.Adam(model.parameters(),lr=0.001)\n",
    "    loss_func = F.cross_entropy\n",
    "    return model,opt,loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            print(xb.shape)\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl])\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        print('当前step:'+str(step), '验证集损失：'+str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e4f8b5efa3bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mOutPutChanels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataGet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGetModelWithOptAndLossFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputChanels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOutPutChanels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-ed1309c8d777>\u001b[0m in \u001b[0;36mGetModelWithOptAndLossFunc\u001b[1;34m(InputChanels, OutPutChanels)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mGetModelWithOptAndLossFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputChanels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOutPutChanels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInputChanels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOutPutChanels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mloss_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "bs = len(x_train)\n",
    "steps = 1\n",
    "InputChanels = x_train.shape[1]\n",
    "OutPutChanels = 1\n",
    "train_dl, valid_dl = DataGet(x_train, x_test, y_train, y_test,bs)\n",
    "model, opt,loss_func = GetModelWithOptAndLossFunc(InputChanels,OutPutChanels)\n",
    "model_fit(steps, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLinearRegression(\n",
      "  (out): Linear(in_features=13, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "InputChanels = x_train.shape[1]\n",
    "OutPutChanels = 1\n",
    "Net = XLinearRegression(InputChanels,OutPutChanels)\n",
    "print(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
